{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 1: Συλλογή Δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H συνάρτηση Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def crawl_wikipedia(url):\n",
    "    data = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Εξαγωγή τίτλου και κειμένου\n",
    "        title = soup.find(\"h1\").text # βρίσκει h1 html tag (header1) και επιστρέφει το κείμενο του\n",
    "        paragraphs = [p.text for p in soup.find_all(\"p\")] # βρίσκει όλα τα p html tags (paragraph) και επιστρέφει το κείμενο τους\n",
    "        content = \"\\n\".join(paragraphs) # διαχωριστής των παραγράφων το σύμβολο \" | \"\n",
    "        data.append({'title': title, 'content': content}) # προσθήκη τίτλου και περιεχομένου στη λίστα data\n",
    "    else: \n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(f\"URL: {url}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Χρηση της συνάρτησης Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Λίστα άρθρων για συλλογή \n",
    "articles = [\n",
    "    \"Science\",\n",
    "    \"Technology\",\n",
    "    \"Engineering\",\n",
    "    \"Mathematics\",\n",
    "]\n",
    "collected_data = []\n",
    "\n",
    "for article in articles:\n",
    "    url = f'https://en.wikipedia.org/wiki/{article}'\n",
    "    collected_data.extend(crawl_wikipedia(url))\n",
    "    # for d in collected_data:\n",
    "    #     words = d['content'].split()\n",
    "    #     d['content'] = \" \".join(words[:500]) # each article is limited to 500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 4\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe.[1][2] '\n",
      " 'Modern science is typically divided into two or three major branches:[3] the '\n",
      " 'natural sciences (e.g., physics, chemistry, and biology), which study the '\n",
      " 'physical world; and the behavioural sciences (e.g., economics, psychology, '\n",
      " 'and sociology), which study individuals and societies.[4][5] The formal '\n",
      " 'sciences (e.g., logic, mathematics, and theoretical computer science), which '\n",
      " 'study formal systems governed by axioms and rules,[6][7] are sometimes '\n",
      " 'described as being sciences as well; however, they are often regarded as a '\n",
      " 'separate field because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def print_article(collected_data):\n",
    "    print(\"Number of articles collected:\", len(collected_data))\n",
    "    print(f\"1.Article Title: {collected_data[0]['title']}\")\n",
    "    print(\"  Content (first 100 words):\")\n",
    "    pprint(\" \".join(collected_data[0]['content'].split()[:100]))\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_json(data, filename):\n",
    "    with open('Files/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# Αποθήκευση δεδομένων σε json αρχείο\n",
    "save_json(collected_data, 'wiki_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_csv(data, filename):\n",
    "    with open('Files/' + filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['title', 'content'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Αποθήκευση δεδομένων σε csv αρχείο\n",
    "save_csv(collected_data, 'wiki_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 2: Προεπεξεργασία Κειμένου (Text Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αφαιρεση πηγών (π.χ. [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 4\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe. Modern '\n",
      " 'science is typically divided into two or three major branches: the natural '\n",
      " 'sciences (e.g., physics, chemistry, and biology), which study the physical '\n",
      " 'world; and the behavioural sciences (e.g., economics, psychology, and '\n",
      " 'sociology), which study individuals and societies. The formal sciences '\n",
      " '(e.g., logic, mathematics, and theoretical computer science), which study '\n",
      " 'formal systems governed by axioms and rules, are sometimes described as '\n",
      " 'being sciences as well; however, they are often regarded as a separate field '\n",
      " 'because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "# Load collected data from CSV\n",
    "collected_data_df = pd.read_csv('Files/wiki_data.csv')\n",
    "collected_data = collected_data_df.to_dict(orient='records')\n",
    "for d in collected_data:\n",
    "    d['content'] = re.sub(r\"\\[\\d+\\]\", \"\", d['content']) # regex για αντικατάσταση πηγών με κενό\n",
    "\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αφαίρεση σημείων στίξης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 4\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe Modern '\n",
      " 'science is typically divided into two or three major branches the natural '\n",
      " 'sciences eg physics chemistry and biology which study the physical world and '\n",
      " 'the behavioural sciences eg economics psychology and sociology which study '\n",
      " 'individuals and societies The formal sciences eg logic mathematics and '\n",
      " 'theoretical computer science which study formal systems governed by axioms '\n",
      " 'and rules are sometimes described as being sciences as well however they are '\n",
      " 'often regarded as a separate field because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "for punct in string.punctuation:\n",
    "    for d in collected_data:\n",
    "        d['content'] = d['content'].replace(punct, '') # αφαίρεση σημείων στίξης\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "tokens = []\n",
    "stemmed_data = []\n",
    "\n",
    "for d in collected_data: # For each article\n",
    "    tokens = word_tokenize(d['content'])  # Tokenize content \n",
    "    stemmed_tokens = [porter.stem(t) for t in tokens]  # Stem each token\n",
    "    stemmed_data.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"stemmed_tokens\": stemmed_tokens\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Article Title: Science\n",
      "Tokens first 20 words: \n",
      "['scienc',\n",
      " 'is',\n",
      " 'a',\n",
      " 'systemat',\n",
      " 'disciplin',\n",
      " 'that',\n",
      " 'build',\n",
      " 'and',\n",
      " 'organis',\n",
      " 'knowledg',\n",
      " 'in',\n",
      " 'the',\n",
      " 'form',\n",
      " 'of',\n",
      " 'testabl',\n",
      " 'hypothes',\n",
      " 'and',\n",
      " 'predict',\n",
      " 'about',\n",
      " 'the']\n"
     ]
    }
   ],
   "source": [
    "def print_tokens(data, tokens):\n",
    "    print(f\"1. Article Title: {data[0]['title']}\")\n",
    "    print(\"Tokens first 20 words: \")\n",
    "    pprint(data[0][tokens][:20])\n",
    "print_tokens(stemmed_data, \"stemmed_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop-word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Article Title: Science\n",
      "Tokens first 20 words: \n",
      "['scienc',\n",
      " 'systemat',\n",
      " 'disciplin',\n",
      " 'build',\n",
      " 'organis',\n",
      " 'knowledg',\n",
      " 'form',\n",
      " 'testabl',\n",
      " 'hypothes',\n",
      " 'predict',\n",
      " 'univers',\n",
      " 'modern',\n",
      " 'scienc',\n",
      " 'typic',\n",
      " 'divid',\n",
      " 'two',\n",
      " 'three',\n",
      " 'major',\n",
      " 'branch',\n",
      " 'natur']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "cleaned_data = []\n",
    "cleaned_data_for_csv = []\n",
    "\n",
    "for d in stemmed_data: # or lemmed_data (one of the two) - Επιλογή μεταξύ stemming και lemmatization??\n",
    "    filtered_tokens = [t for t in d['stemmed_tokens'] if t.lower() not in stopwords]\n",
    "    cleaned_data.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"cleaned_tokens\": filtered_tokens\n",
    "    })\n",
    "    cleaned_data_for_csv.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"content\": \" \".join(filtered_tokens)\n",
    "    })\n",
    "    \n",
    "print_tokens(cleaned_data, \"cleaned_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε .json και .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(cleaned_data, 'wiki_data_cleaned.json')\n",
    "save_csv(cleaned_data_for_csv, 'wiki_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 3: Ευρετήριο (Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engin</th>\n",
       "      <th>practic</th>\n",
       "      <th>use</th>\n",
       "      <th>natur</th>\n",
       "      <th>scienc</th>\n",
       "      <th>mathemat</th>\n",
       "      <th>design</th>\n",
       "      <th>process</th>\n",
       "      <th>solv</th>\n",
       "      <th>technic</th>\n",
       "      <th>problem</th>\n",
       "      <th>increas</th>\n",
       "      <th>effici</th>\n",
       "      <th>product</th>\n",
       "      <th>improv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>229</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematics</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>131</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             engin  practic  use  natur  scienc  mathemat  design  process  \\\n",
       "Engineering    229       16   40      5      25        10      47       14   \n",
       "Mathematics      2        5   64     13      28       242       2        2   \n",
       "Science          5       10   30     46     131        14       2       10   \n",
       "Technology      13        8   45      9       9         0       3        5   \n",
       "\n",
       "             solv  technic  problem  increas  effici  product  improv  \n",
       "Engineering     3        7       10        5       3       21       5  \n",
       "Mathematics    14        3       25        2       0        0       0  \n",
       "Science         4        3        7        5       1        3       8  \n",
       "Technology      0        1        1       13       0        7       7  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('Files/wiki_data_cleaned.json', 'r') as file:\n",
    "    wiki_data = json.load(file)\n",
    "\n",
    "corpus = {}\n",
    "for i, entry in enumerate(wiki_data):\n",
    "    title = entry.get(\"title\", f\"sent{i}\") \n",
    "    tokens = entry.get(\"cleaned_tokens\", [])\n",
    "    corpus[title] = {token: tokens.count(token) for token in tokens}\n",
    "\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "print(\"First 15 columns:\")\n",
    "df.iloc[:, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε .json και .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Files/wiki_data_inverted_index.csv')\n",
    "df.to_json('Files/wiki_data_inverted_index.json', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 4: Μηχανή αναζήτησης (Search Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Επεξεργασία ερωτήματος (Query Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Λειτουργίες μηχανής αναζήτησης\n",
    "def boolean_query(query, index):\n",
    "    \"\"\"Εκτελεί Boolean αναζήτηση (AND, OR, NOT)\"\"\"\n",
    "    terms = query.split()\n",
    "    result_sets = []\n",
    "\n",
    "    for term in terms:\n",
    "        if term in index:\n",
    "            result_sets.append(set(index[term]))\n",
    "        elif term.upper() == \"AND\":\n",
    "            continue\n",
    "        elif term.upper() == \"OR\":\n",
    "            continue\n",
    "        else:\n",
    "            result_sets.append(set())\n",
    "\n",
    "    result = set.intersection(*result_sets) if \"AND\" in terms else set.union(*result_sets)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Κατάταξη αποτελεσμάτων (Ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Preprocess the input query (tokenize and stem)\n",
    "def preprocess_query(query):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(query.lower())  # Tokenize and lowercased\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Function to calculate TF-IDF\n",
    "def calculate_tfidf(query, inverted_index):\n",
    "    # Preprocess query\n",
    "    query_tokens = preprocess_query(query)\n",
    "\n",
    "    # Build the corpus from the inverted index\n",
    "    corpus = []\n",
    "    document_names = list(next(iter(inverted_index.values())).keys())  # Extract document names\n",
    "\n",
    "    # Create the document-term matrix\n",
    "    for doc in document_names:\n",
    "        doc_str = \" \".join(\n",
    "            [term for term, docs in inverted_index.items() if doc in docs and docs[doc] > 0]\n",
    "        )\n",
    "        corpus.append(doc_str)\n",
    "\n",
    "    # Apply TF-IDF using TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Query TF-IDF transformation\n",
    "    query_vector = vectorizer.transform([\" \".join(query_tokens)])\n",
    "\n",
    "    # Calculate cosine similarity between query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vector, X).flatten()\n",
    "\n",
    "    # Rank documents based on cosine similarity\n",
    "    ranked_docs = sorted(zip(cosine_similarities, document_names), reverse=True)\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 5. Αξιολόγηση συστήματος:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αξιολόγηση συστήματος με Precision, Recall, F1, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(queries, relevant_docs, retrieval_function):\n",
    "    \"\"\"Αξιολόγηση συστήματος με Precision, Recall, F1, MAP\"\"\"\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    average_precision_list = []\n",
    "\n",
    "    for query, relevant in zip(queries, relevant_docs):\n",
    "        results = retrieval_function(query, inverted_index, articles)\n",
    "        retrieved_docs = [doc for doc, _ in results]\n",
    "\n",
    "        true_positives = len(set(retrieved_docs) & set(relevant))\n",
    "        precision = true_positives / len(retrieved_docs) if retrieved_docs else 0\n",
    "        recall = true_positives / len(relevant) if relevant else 0\n",
    "        f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Υπολογισμός Μέσης Ακρίβειας (AP)\n",
    "        cumulative_precision = 0\n",
    "        for rank, doc in enumerate(retrieved_docs, start=1):\n",
    "            if doc in relevant:\n",
    "                cumulative_precision += len(set(retrieved_docs[:rank]) & set(relevant)) / rank\n",
    "        average_precision = cumulative_precision / len(relevant) if relevant else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        average_precision_list.append(average_precision)\n",
    "\n",
    "    mean_precision = sum(precision_list) / len(precision_list)\n",
    "    mean_recall = sum(recall_list) / len(recall_list)\n",
    "    mean_f1 = sum(f1_list) / len(f1_list)\n",
    "    mean_average_precision = sum(average_precision_list) / len(average_precision_list)\n",
    "\n",
    "    return {\n",
    "        \"Precision\": mean_precision,\n",
    "        \"Recall\": mean_recall,\n",
    "        \"F1\": mean_f1,\n",
    "        \"MAP\": mean_average_precision\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Διεπαφή Χρήστη (User Interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Διάβασμα άρθρων και ευρετηρίου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "user_queries = []\n",
    "user_relevant_docs = []\n",
    "\n",
    "# Load articles\n",
    "with open(\"Files/wiki_data_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "# Load inverted index\n",
    "with open(\"Files/wiki_data_inverted_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inverted_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_interface():\n",
    "    print(\"Καλώς ήρθατε στη μηχανή αναζήτησης!\\n\")\n",
    "    while True:\n",
    "        print(\"1. Boolean Αναζήτηση\")\n",
    "        print(\"2. Αναζήτηση με κατάταξη TF-IDF\")\n",
    "        print(\"3. Αναζήτηση με κατάταξη BM25\")\n",
    "        print(\"4. Αξιολόγηση Συστήματος\")\n",
    "        print(\"5. Έξοδος\")\n",
    "        \n",
    "        choice = input(\"Επιλέξτε επιλογή:\")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            query = input(\"Εισάγετε το Boolean ερώτημά σας (π.χ. term1 AND term2): \")\n",
    "            results = boolean_query(query, inverted_index)\n",
    "            if results:\n",
    "                print(\"Αποτελέσματα:\")\n",
    "                for res in results:\n",
    "                    print(res)\n",
    "                user_queries.append(query)\n",
    "                user_relevant_docs.append(list(results))\n",
    "            else:\n",
    "                print(\"Δεν βρέθηκαν αποτελέσματα.\")\n",
    "        elif choice == \"2\":\n",
    "            query = input(\"Εισάγετε το ερώτημά σας: \")\n",
    "            print(\"---Αποτελέσματα TF-IDF---\")\n",
    "            print(\"Query given:\", query)\n",
    "            ranked_docs = calculate_tfidf(query, inverted_index)\n",
    "            if ranked_docs:\n",
    "                for score, doc in ranked_docs:\n",
    "                    print(f\"Document: {doc}, Score: {score:.4f}\")\n",
    "            else:\n",
    "                print(\"Δεν βρέθηκαν αποτελέσματα.\")\n",
    "        elif choice == \"5\":\n",
    "            print(\"Ευχαριστούμε που χρησιμοποιήσατε τη μηχανή αναζήτησης!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Μη έγκυρη επιλογή. Δοκιμάστε ξανά.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Διεπαφή χρήστη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interface()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
