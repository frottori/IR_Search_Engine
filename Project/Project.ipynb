{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 1: Συλλογή Δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H συνάρτηση Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def crawl_wikipedia(url):\n",
    "    data = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Εξαγωγή τίτλου και κειμένου\n",
    "        title = soup.find(\"h1\").text # βρίσκει h1 html tag (header1) και επιστρέφει το κείμενο του\n",
    "        paragraphs = [p.text for p in soup.find_all(\"p\")] # βρίσκει όλα τα p html tags (paragraph) και επιστρέφει το κείμενο τους\n",
    "        content = \"\\n\".join(paragraphs) # διαχωριστής των παραγράφων το σύμβολο \" | \"\n",
    "        data.append({'title': title, 'content': content}) # προσθήκη τίτλου και περιεχομένου στη λίστα data\n",
    "    else: \n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(f\"URL: {url}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Χρηση της συνάρτησης Crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Λίστα άρθρων για συλλογή \n",
    "articles = [\n",
    "    \"Science\",\n",
    "    \"Technology\",\n",
    "    \"Engineering\",\n",
    "    \"Mathematics\",\n",
    "    \"Artificial_intelligence\",\n",
    "    \"Machine_learning\",\n",
    "    \"Deep_learning\",\n",
    "    \"Data_science\",\n",
    "    \"Computer_science\",\n",
    "    \"Programming_language\",\n",
    "    \"Software_engineering\",\n",
    "    \"Operating_system\",\n",
    "    \"Computer_network\",\n",
    "    \"Internet\",\n",
    "]\n",
    "collected_data = []\n",
    "\n",
    "for article in articles:\n",
    "    url = f'https://en.wikipedia.org/wiki/{article}'\n",
    "    collected_data.extend(crawl_wikipedia(url))\n",
    "    # for d in collected_data:\n",
    "    #     words = d['content'].split()\n",
    "    #     d['content'] = \" \".join(words[:500]) # each article is limited to 500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 14\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe.[1][2] '\n",
      " 'Modern science is typically divided into two or three major branches:[3] the '\n",
      " 'natural sciences (e.g., physics, chemistry, and biology), which study the '\n",
      " 'physical world; and the behavioural sciences (e.g., economics, psychology, '\n",
      " 'and sociology), which study individuals and societies.[4][5] The formal '\n",
      " 'sciences (e.g., logic, mathematics, and theoretical computer science), which '\n",
      " 'study formal systems governed by axioms and rules,[6][7] are sometimes '\n",
      " 'described as being sciences as well; however, they are often regarded as a '\n",
      " 'separate field because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def print_article(collected_data):\n",
    "    print(\"Number of articles collected:\", len(collected_data))\n",
    "    print(f\"1.Article Title: {collected_data[0]['title']}\")\n",
    "    print(\"  Content (first 100 words):\")\n",
    "    pprint(\" \".join(collected_data[0]['content'].split()[:100]))\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_json(data, filename):\n",
    "    with open('Files/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "# Αποθήκευση δεδομένων σε json αρχείο\n",
    "save_json(collected_data, 'wiki_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_csv(data, filename):\n",
    "    with open('Files/' + filename, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['title', 'content'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Αποθήκευση δεδομένων σε csv αρχείο\n",
    "save_csv(collected_data, 'wiki_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 2: Προεπεξεργασία Κειμένου (Text Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αφαιρεση πηγών (π.χ. [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 14\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe. Modern '\n",
      " 'science is typically divided into two or three major branches: the natural '\n",
      " 'sciences (e.g., physics, chemistry, and biology), which study the physical '\n",
      " 'world; and the behavioural sciences (e.g., economics, psychology, and '\n",
      " 'sociology), which study individuals and societies. The formal sciences '\n",
      " '(e.g., logic, mathematics, and theoretical computer science), which study '\n",
      " 'formal systems governed by axioms and rules, are sometimes described as '\n",
      " 'being sciences as well; however, they are often regarded as a separate field '\n",
      " 'because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "# Load collected data from CSV\n",
    "collected_data_df = pd.read_csv('Files/wiki_data.csv')\n",
    "collected_data = collected_data_df.to_dict(orient='records')\n",
    "for d in collected_data:\n",
    "    d['content'] = re.sub(r\"\\[\\d+\\]\", \"\", d['content']) # regex για αντικατάσταση πηγών με κενό\n",
    "\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αφαίρεση σημείων στίξης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles collected: 14\n",
      "1.Article Title: Science\n",
      "  Content (first 100 words):\n",
      "('Science is a systematic discipline that builds and organises knowledge in '\n",
      " 'the form of testable hypotheses and predictions about the universe Modern '\n",
      " 'science is typically divided into two or three major branches the natural '\n",
      " 'sciences eg physics chemistry and biology which study the physical world and '\n",
      " 'the behavioural sciences eg economics psychology and sociology which study '\n",
      " 'individuals and societies The formal sciences eg logic mathematics and '\n",
      " 'theoretical computer science which study formal systems governed by axioms '\n",
      " 'and rules are sometimes described as being sciences as well however they are '\n",
      " 'often regarded as a separate field because they rely on deductive')\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "for punct in string.punctuation:\n",
    "    for d in collected_data:\n",
    "        d['content'] = d['content'].replace(punct, '') # αφαίρεση σημείων στίξης\n",
    "print_article(collected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "porter = nltk.PorterStemmer()\n",
    "\n",
    "tokens = []\n",
    "stemmed_data = []\n",
    "\n",
    "for d in collected_data: # For each article\n",
    "    tokens = word_tokenize(d['content'])  # Tokenize content \n",
    "    stemmed_tokens = [porter.stem(t) for t in tokens]  # Stem each token\n",
    "    stemmed_data.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"stemmed_tokens\": stemmed_tokens\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Article Title: Science\n",
      "Tokens first 20 words: \n",
      "['scienc',\n",
      " 'is',\n",
      " 'a',\n",
      " 'systemat',\n",
      " 'disciplin',\n",
      " 'that',\n",
      " 'build',\n",
      " 'and',\n",
      " 'organis',\n",
      " 'knowledg',\n",
      " 'in',\n",
      " 'the',\n",
      " 'form',\n",
      " 'of',\n",
      " 'testabl',\n",
      " 'hypothes',\n",
      " 'and',\n",
      " 'predict',\n",
      " 'about',\n",
      " 'the']\n"
     ]
    }
   ],
   "source": [
    "def print_tokens(data, tokens):\n",
    "    print(f\"1. Article Title: {data[0]['title']}\")\n",
    "    print(\"Tokens first 20 words: \")\n",
    "    pprint(data[0][tokens][:20])\n",
    "print_tokens(stemmed_data, \"stemmed_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop-word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Article Title: Science\n",
      "Tokens first 20 words: \n",
      "['scienc',\n",
      " 'systemat',\n",
      " 'disciplin',\n",
      " 'build',\n",
      " 'organis',\n",
      " 'knowledg',\n",
      " 'form',\n",
      " 'testabl',\n",
      " 'hypothes',\n",
      " 'predict',\n",
      " 'univers',\n",
      " 'modern',\n",
      " 'scienc',\n",
      " 'typic',\n",
      " 'divid',\n",
      " 'two',\n",
      " 'three',\n",
      " 'major',\n",
      " 'branch',\n",
      " 'natur']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "cleaned_data = []\n",
    "cleaned_data_for_csv = []\n",
    "\n",
    "for d in stemmed_data: # or lemmed_data (one of the two) - Επιλογή μεταξύ stemming και lemmatization??\n",
    "    filtered_tokens = [t for t in d['stemmed_tokens'] if t.lower() not in stopwords]\n",
    "    cleaned_data.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"cleaned_tokens\": filtered_tokens\n",
    "    })\n",
    "    cleaned_data_for_csv.append({\n",
    "        \"title\": d[\"title\"],\n",
    "        \"content\": \" \".join(filtered_tokens)\n",
    "    })\n",
    "    \n",
    "print_tokens(cleaned_data, \"cleaned_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε .json και .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(cleaned_data, 'wiki_data_cleaned.json')\n",
    "save_csv(cleaned_data_for_csv, 'wiki_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 3: Ευρετήριο (Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artifici</th>\n",
       "      <th>intellig</th>\n",
       "      <th>ai</th>\n",
       "      <th>broadest</th>\n",
       "      <th>sens</th>\n",
       "      <th>exhibit</th>\n",
       "      <th>machin</th>\n",
       "      <th>particularli</th>\n",
       "      <th>comput</th>\n",
       "      <th>system</th>\n",
       "      <th>field</th>\n",
       "      <th>research</th>\n",
       "      <th>scienc</th>\n",
       "      <th>develop</th>\n",
       "      <th>studi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Artificial intelligence</th>\n",
       "      <td>41</td>\n",
       "      <td>73</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer network</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer science</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data science</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep learning</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engineering</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internet</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machine learning</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathematics</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operating system</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Programming language</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>131</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software engineering</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         artifici  intellig   ai  broadest  sens  exhibit  \\\n",
       "Artificial intelligence        41        73  221         1     4        3   \n",
       "Computer network                0         0    0         0     0        1   \n",
       "Computer science                6         8    2         0     0        0   \n",
       "Data science                    0         0    0         0     0        0   \n",
       "Deep learning                  13         4    8         0     1        0   \n",
       "Engineering                     3         1    0         0     1        2   \n",
       "Internet                        0         1    0         0     0        1   \n",
       "Machine learning               28        13   23         0     0        1   \n",
       "Mathematics                     0         0    0         0     1        0   \n",
       "Operating system                0         0    0         0     0        0   \n",
       "Programming language            1         1    0         0     0        1   \n",
       "Science                         2         1    0         0     4        1   \n",
       "Software engineering            1         1    0         0     0        0   \n",
       "Technology                      6         7   10         0     1        0   \n",
       "\n",
       "                         machin  particularli  comput  system  field  \\\n",
       "Artificial intelligence      59             5      41      34     22   \n",
       "Computer network              2             0      48      17      1   \n",
       "Computer science             13             0     166      28     15   \n",
       "Data science                  6             0      16       4     18   \n",
       "Deep learning                25             4      35      38      8   \n",
       "Engineering                  28             0      13      21     15   \n",
       "Internet                      0             0      43      26      5   \n",
       "Machine learning            119             3      37      40     24   \n",
       "Mathematics                   0             4      23      13     11   \n",
       "Operating system              8             0      48     166      0   \n",
       "Programming language         13             1      30      11      3   \n",
       "Science                       3             0       9      11     13   \n",
       "Software engineering          0             0      33       7     10   \n",
       "Technology                    8             2      12       8      6   \n",
       "\n",
       "                         research  scienc  develop  studi  \n",
       "Artificial intelligence        53       6       36     11  \n",
       "Computer network                2       1        3      1  \n",
       "Computer science               10      70       13     22  \n",
       "Data science                    3      56        4      0  \n",
       "Deep learning                  19       4       19      1  \n",
       "Engineering                     6      25       40     12  \n",
       "Internet                       23       5       19     11  \n",
       "Machine learning               20       3        7     11  \n",
       "Mathematics                     4      28       23     47  \n",
       "Operating system                1       0       14      0  \n",
       "Programming language            2       2        9      1  \n",
       "Science                        53     131       28     24  \n",
       "Software engineering            4      13       26      1  \n",
       "Technology                     17       9       19      8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('Files/wiki_data_cleaned.json', 'r', encoding='utf-8') as file:\n",
    "    wiki_data = json.load(file)\n",
    "\n",
    "corpus = {}\n",
    "for i, entry in enumerate(wiki_data):\n",
    "    title = entry.get(\"title\", f\"sent{i}\") \n",
    "    tokens = entry.get(\"cleaned_tokens\", [])\n",
    "    corpus[title] = {token: tokens.count(token) for token in tokens}\n",
    "\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "print(\"First 15 columns:\")\n",
    "df.iloc[:, :15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αποθήκευση σε .json και .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Files/wiki_data_inverted_index.csv')\n",
    "df.to_json('Files/wiki_data_inverted_index.json', indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 4: Μηχανή αναζήτησης (Search Engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Επεξεργασία ερωτήματος (Query Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Λειτουργίες μηχανής αναζήτησης\n",
    "def boolean_query(query, index):\n",
    "    \"\"\"Boolean (AND, OR, NOT)\"\"\"\n",
    "    terms = query.split()\n",
    "    result_sets = []\n",
    "\n",
    "    for term in terms:\n",
    "        if term in index:\n",
    "            stemmer = PorterStemmer()\n",
    "            term = stemmer.stem(term)\n",
    "            result_sets.append(set(index[term]))\n",
    "        elif term.upper() == \"AND\":\n",
    "            continue\n",
    "        elif term.upper() == \"OR\":\n",
    "            continue\n",
    "        else:\n",
    "            result_sets.append(set())\n",
    "\n",
    "    result = set.intersection(*result_sets) if \"AND\" in terms else set.union(*result_sets)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Κατάταξη αποτελεσμάτων (Ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Function to calculate TF-IDF\n",
    "def tf_idf_retrieval(query, inverted_index):\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(query.lower())  # Tokenize and lowercased\n",
    "    query_tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # Build the corpus from the inverted index\n",
    "    corpus = []\n",
    "    document_names = list(next(iter(inverted_index.values())).keys())  # Extract document names\n",
    "\n",
    "    # Create the document-term matrix\n",
    "    for doc in document_names:\n",
    "        doc_str = \" \".join(\n",
    "            [term for term, docs in inverted_index.items() if doc in docs and docs[doc] > 0]\n",
    "        )\n",
    "        corpus.append(doc_str)\n",
    "\n",
    "    # Apply TF-IDF using TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Query TF-IDF transformation\n",
    "    query_vector = vectorizer.transform([\" \".join(query_tokens)])\n",
    "\n",
    "    # Calculate cosine similarity between query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vector, X).flatten()\n",
    "\n",
    "    # Rank documents based on cosine similarity, excluding those with a score of 0\n",
    "    ranked_docs = sorted(\n",
    "        [(score, doc) for score, doc in zip(cosine_similarities, document_names) if score > 0],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Vector Space Model (VSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def vsm_retrieval(query, inverted_index):\n",
    "    # Preprocess the inverted index into a format suitable for TF-IDF processing\n",
    "    documents = {}\n",
    "    for term, doc_scores in inverted_index.items():\n",
    "        for doc, score in doc_scores.items():\n",
    "            if doc not in documents:\n",
    "                documents[doc] = \"\"\n",
    "            documents[doc] += (term + \" \") * score\n",
    "\n",
    "    doc_names = list(documents.keys())  # Extract document names\n",
    "    doc_texts = list(documents.values())  # Extract document texts\n",
    "\n",
    "    # Preprocess the query using stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    query_tokens = word_tokenize(query.lower())\n",
    "    query_stemmed = \" \".join([stemmer.stem(token) for token in query_tokens])\n",
    "\n",
    "    # Create a TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit the documents and transform both documents and query\n",
    "    tfidf_matrix = vectorizer.fit_transform(doc_texts)\n",
    "    query_vector = vectorizer.transform([query_stemmed])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Rank documents based on similarity scores, excluding those with a score of 0\n",
    "    ranked_docs = sorted(\n",
    "        [(doc_names[doc_idx], score) for doc_idx, score in enumerate(similarities) if score > 0],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okapi BM25 (Probabilistic retrieval model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Function to calculate BM25 scores\n",
    "def bm25_score(inverted_index, query, k1=1.5, b=0.75):\n",
    "    # Initialize stemmer and preprocess the query\n",
    "    stemmer = PorterStemmer()\n",
    "    query_terms = [stemmer.stem(term) for term in query.lower().split()]\n",
    "\n",
    "    # Flatten inverted index to document-term matrix\n",
    "    documents = {}\n",
    "    for term, doc_scores in inverted_index.items():\n",
    "        for doc, score in doc_scores.items():\n",
    "            if doc not in documents:\n",
    "                documents[doc] = {}\n",
    "            documents[doc][term] = score\n",
    "\n",
    "    # Document lengths and average document length\n",
    "    doc_lengths = {doc: sum(terms.values()) for doc, terms in documents.items()}\n",
    "    avg_doc_length = np.mean(list(doc_lengths.values()))\n",
    "\n",
    "    # BM25 calculation\n",
    "    N = len(documents)  # Total number of documents\n",
    "    scores = {doc: 0 for doc in documents}\n",
    "\n",
    "    for term in query_terms:\n",
    "        if term in inverted_index:\n",
    "            n_q = len(inverted_index[term])  # Number of documents containing the term\n",
    "            idf = math.log((N - n_q + 0.5) / (n_q + 0.5) + 1)  # IDF for the term\n",
    "\n",
    "            for doc, freq in inverted_index[term].items():\n",
    "                term_freq = freq\n",
    "                doc_length = doc_lengths[doc]\n",
    "\n",
    "                # BM25 formula\n",
    "                numerator = term_freq * (k1 + 1)\n",
    "                denominator = term_freq + k1 * (1 - b + b * (doc_length / avg_doc_length))\n",
    "                scores[doc] += idf * (numerator / denominator)\n",
    "\n",
    "    # Sort documents by score, excluding those with a score of 0\n",
    "    ranked_docs = sorted(\n",
    "        [(doc, score) for doc, score in scores.items() if score > 0],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Βήμα 5. Αξιολόγηση συστήματος:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Αξιολόγηση συστήματος με Precision, Recall, F1, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_retrieval(results, docs):\n",
    "    \n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    map_scores = []\n",
    "    \n",
    "    for query, retrieved_docs in results.items():\n",
    "        relevant_docs = set(docs[query])\n",
    "        retrieved_docs = set(retrieved_docs)\n",
    "        \n",
    "        # Precision, Recall, F1-Score\n",
    "        num_relevant_retrieved = len(relevant_docs & retrieved_docs)\n",
    "        num_retrieved = len(retrieved_docs)\n",
    "        num_relevant = len(relevant_docs)\n",
    "        \n",
    "        precision = num_relevant_retrieved / num_retrieved if num_retrieved > 0 else 0\n",
    "        recall = num_relevant_retrieved / num_relevant if num_relevant > 0 else 0\n",
    "        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # MAP\n",
    "        sorted_retrieved = list(retrieved_docs)\n",
    "        ap = 0\n",
    "        relevant_count = 0\n",
    "        \n",
    "        for i, doc in enumerate(sorted_retrieved, 1):\n",
    "            if doc in relevant_docs:\n",
    "                relevant_count += 1\n",
    "                ap += relevant_count / i\n",
    "        \n",
    "        ap /= len(relevant_docs) if len(relevant_docs) > 0 else 1\n",
    "        map_scores.append(ap)\n",
    "    \n",
    "    # Compute averages\n",
    "    avg_precision = sum(precision_scores) / len(precision_scores)\n",
    "    avg_recall = sum(recall_scores) / len(recall_scores)\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    mean_ap = sum(map_scores) / len(map_scores)\n",
    "\n",
    "    evaluation_results = {\n",
    "        \"Precision\": avg_precision,\n",
    "        \"Recall\": avg_recall,\n",
    "        \"F1-Score\": avg_f1,\n",
    "        \"MAP\": mean_ap\n",
    "    }\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Διεπαφή Χρήστη (User Interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Διάβασμα άρθρων και ευρετηρίου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load articles\n",
    "with open(\"Files/wiki_data_cleaned.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "# Load inverted index\n",
    "with open(\"Files/wiki_data_inverted_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inverted_index = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Διεπαφή χρήστη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_results = {}\n",
    "tf_queries = {}\n",
    "vsm_results = {}\n",
    "vsm_queries = {}\n",
    "bm25_results = {}\n",
    "bm25_queries = {}\n",
    "\n",
    "def user_interface():\n",
    "    while True:\n",
    "        questions = [\n",
    "            \"---------------Search Engine Menu---------------\",\n",
    "            \"1. Boolean search\",\n",
    "            \"2. TF-IDF Ranking\",\n",
    "            \"3. Vector Space Model Ranking\",\n",
    "            \"4. BM25 Ranking\",\n",
    "            \"5. Evaluate System\",\n",
    "            \"6. Exit\",\n",
    "        ]\n",
    "        print(\"\\n\".join(questions))\n",
    "        choice = input(\"Choose:\")\n",
    "\n",
    "        article_titles = [article[\"title\"] for article in articles]\n",
    "\n",
    "        if choice == \"1\":\n",
    "            query = input(\"Input Boolean query (e.g. term1 AND term2): \")\n",
    "            results = boolean_query(query, inverted_index)\n",
    "            if not results:\n",
    "                print(\"No results found.\")\n",
    "                break\n",
    "\n",
    "            print(\"Αποτελέσματα:\")\n",
    "            for res in results:\n",
    "                print(res)\n",
    "        elif choice == \"2\":\n",
    "            query = input(\"Input query:\")\n",
    "            print(\"---------------Results TF-IDF---------------\")\n",
    "            print(\"Query given:\", query)\n",
    "            ranked_docs = tf_idf_retrieval(query, inverted_index)\n",
    "            if not ranked_docs:\n",
    "                print(\"No results found.\")\n",
    "                break\n",
    "\n",
    "            for score, doc in ranked_docs:\n",
    "                    print(f\"Document: {doc}, Score: {score:.4f}\")\n",
    "            tf_results[query] = [doc for _, doc in ranked_docs]\n",
    "            tf_queries[query] = article_titles\n",
    "        elif choice == \"3\":\n",
    "            query = input(\"Input query:\")\n",
    "            print(\"---------------Results Vector Space Model---------------\")\n",
    "            print(\"Query given:\", query)\n",
    "            ranked_docs = vsm_retrieval(query, inverted_index)\n",
    "            if not ranked_docs:\n",
    "                print(\"No results found.\")\n",
    "                break\n",
    "\n",
    "            for doc, score in ranked_docs:\n",
    "                print(f\"Document: {doc}, Score: {score:.4f}\")\n",
    "            vsm_results[query] = [doc for doc, _ in ranked_docs]\n",
    "            vsm_queries[query] = article_titles\n",
    "        elif choice == \"4\":\n",
    "            query = input(\"Input query:\")\n",
    "            print(\"---------------Results BM25---------------\")\n",
    "            print(\"Query given:\", query)\n",
    "            ranked_docs = bm25_score(inverted_index, query)\n",
    "            if not ranked_docs:\n",
    "                print(\"No results found.\")\n",
    "                break\n",
    "\n",
    "            for doc, score in ranked_docs:\n",
    "                print(f\"Document: {doc}, Score: {score:.4f}\")\n",
    "            bm25_results[query] = [doc for doc, _ in ranked_docs]\n",
    "            bm25_queries[query] = article_titles\n",
    "        elif choice == \"5\":\n",
    "\n",
    "            print(\"Αξιολόγηση TF-IDF:\")\n",
    "            if tf_results:\n",
    "                tf_idf_results = evaluate_retrieval(tf_results, tf_queries)\n",
    "                for metric, value in tf_idf_results.items():\n",
    "                    print(f\"{metric}: {value:.4f}\")\n",
    "            else:   \n",
    "                print(\"Δεν υπάρχουν αποτελέσματα για αξιολόγηση.\")\n",
    "\n",
    "            print(\"Αξιολόγηση VSM:\")\n",
    "            if vsm_results:\n",
    "                results = evaluate_retrieval(vsm_results, vsm_queries)\n",
    "                for metric, value in results.items():\n",
    "                    print(f\"{metric}: {value:.4f}\")\n",
    "            else:\n",
    "                print(\"Δεν υπάρχουν αποτελέσματα για αξιολόγηση.\")\n",
    "\n",
    "            print(\"Αξιολόγηση BM25:\")\n",
    "            if bm25_results:\n",
    "                results = evaluate_retrieval(bm25_results, bm25_queries)\n",
    "                for metric, value in results.items():\n",
    "                    print(f\"{metric}: {value:.4f}\")\n",
    "            else:\n",
    "                print(\"Δεν υπάρχουν αποτελέσματα για αξιολόγηση.\")\n",
    "\n",
    "        elif choice == \"6\" or choice == \"\": \n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Search Engine Menu---------------\n",
      "1. Boolean search\n",
      "2. TF-IDF Ranking\n",
      "3. Vector Space Model Ranking\n",
      "4. BM25 Ranking\n",
      "5. Evaluate System\n",
      "6. Exit\n",
      "---------------Results TF-IDF---------------\n",
      "Query given: 6\n",
      "No results found.\n"
     ]
    }
   ],
   "source": [
    "user_interface()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
